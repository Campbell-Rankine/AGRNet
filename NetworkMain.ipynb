{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4c0901a-393d-44d3-984e-5a91c421bd38",
   "metadata": {},
   "source": [
    "# Construct GAN and structure\n",
    "---\n",
    "Construct GAN, define training loop with multithreaded approach, and practice using industry standard terminal initialization commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "7506e300-805a-45d3-bad0-681763121f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### - IMPORTS - ###\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import glob\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from multiprocessing.dummy import Pool as TP\n",
    "import keras.preprocessing.image\n",
    "import cv2 as cv\n",
    "import os\n",
    "import random\n",
    "### - other data augmentation imports - ### (if needed)\n",
    "### - Imports - ###\n",
    "import math\n",
    "import numpy as np\n",
    "import sklearn as sk #general imports, initial data preprocessing/OS stuff\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import os\n",
    "import torch as T\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim #Neural network imports, multiply data etc\n",
    "from torchvision.transforms import ToTensor\n",
    "import torchvision.models as models\n",
    "import torchvision\n",
    "import torch.nn.functional as F #Neural Network used in Comp4660 at ANU\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler #normalize data\n",
    "from sklearn.metrics import confusion_matrix #analysis\n",
    "\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "\n",
    "from Utils.NetworkHelpers import EqualizedLR_Conv2d, Pixel_norm, Minibatch_std\n",
    "\n",
    "### - Other global variables - ###\n",
    "LOVTV = [15, 26, 66] ##Training values to leave out\n",
    "\n",
    "img_folder = '/Users/campb/Documents/PersonalProjects/AGRNet/Dataset/'\n",
    "\n",
    "NS = '/Sample-'\n",
    "\n",
    "image_format = 'RGB'\n",
    "\n",
    "imsize = 4\n",
    "\n",
    "multiplication_factor = 20\n",
    "\n",
    "num_channels=3\n",
    "kernal=4\n",
    "s=2\n",
    "p=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "b0c98949-eda6-42ac-a278-9bb661ca8b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x19fabaf3a90>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### - Get image Paths - ###\n",
    "assert(os.path.exists(DFP + str(1) + \".jpg\"))\n",
    "rawimgf = sorted(glob.glob(DFP + '*.jpg', recursive = True))\n",
    "### - image names - ###\n",
    "imnames = [i.split('/')[-1].split(\"t\")[-1][1:] for i in rawimgf]\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "manualSeed = 999\n",
    "#manualSeed = random.randint(1, 10000) # use if you want new results\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "T.manual_seed(manualSeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "175a67da-9189-42b8-83b0-0e5726b26d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self,img_folder,names, transform):\n",
    "        self.transform = transform\n",
    "        self.image_names = names #Predetermined dataset\n",
    "        self.img_folder=img_folder\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_names)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "    \n",
    "        image=cv.imread(self.img_folder+self.image_names[index])\n",
    "        image=cv.cvtColor(image,cv.COLOR_BGR2RGB)\n",
    "        image=self.transform(image)\n",
    "        \n",
    "        return image\n",
    "\n",
    "    \n",
    "### - Global data loader Vars - ###\n",
    "norms = (0.5,0.5,0.5), (0.5,0.5,0.5)\n",
    "train_transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Resize((imsize, imsize)),\n",
    "                transforms.RandomHorizontalFlip(p=0.5)])\n",
    "\n",
    "# CUDA for PyTorch\n",
    "use_cuda = T.cuda.is_available()\n",
    "device = T.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "T.backends.cudnn.benchmark = True\n",
    "\n",
    "# Parameters\n",
    "params = {'batch_size': 32,\n",
    "          'shuffle': True}\n",
    "\n",
    "train_dataset=ImageDataset(img_folder,imnames, train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "35761ff3-ff0f-42ee-98a0-28a8829203a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_dataset, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "34ac2fc0-5bdf-4922-95bf-deb268c997e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def denorm(img_tensors):\n",
    "    return img_tensors * stats[1][0] + stats[0][0]\n",
    "def imshow(inp, title=None):\n",
    "    \"\"\"imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "# Get a batch of training data\n",
    "images = next(iter(train_dl))\n",
    "\n",
    "# Make a grid from batch\n",
    "output = torchvision.utils.make_grid(images)\n",
    "\n",
    "imshow(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "06613b12-0e29-4d05-b82d-66eebf2bd857",
   "metadata": {},
   "outputs": [],
   "source": [
    "### - Send data to the correct device - ###\n",
    "def to_device(data, device):\n",
    "    if isinstance(data, (list, tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DDL():\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for x in self.dl:\n",
    "            yield to_device(x, self.device)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "aca6c46c-24d0-4410-80aa-2c5217d14d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "9c37d651-5d63-4203-95a8-6b94b1b131dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainddl = DDL(train_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "f95f409c-5955-47eb-8d6e-e4299d3538dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### - Train help functions - ###\n",
    "#Cyclic LR Scheduler\n",
    "class CyclicLR(_LRScheduler):\n",
    "    \n",
    "    def __init__(self, optimizer, schedule, last_epoch=-1):\n",
    "        assert callable(schedule)\n",
    "        self.schedule = schedule\n",
    "        super().__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self):\n",
    "        return [self.schedule(self.last_epoch, lr) for lr in self.base_lrs]\n",
    "\n",
    "def cosine(t_max, eta_min=0):\n",
    "    \n",
    "    def scheduler(epoch, base_lr):\n",
    "        t = epoch % t_max\n",
    "        return eta_min + (base_lr - eta_min)*(1 + np.cos(np.pi*t/t_max))/2\n",
    "    \n",
    "    return scheduler\n",
    "\n",
    "factors = [1, 1, 1, 1, 1/2, 1/4, 1/8, 1/16, 1/32]\n",
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "class fRGB(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "        self.cvt = EqualizedLR_Conv2d(in_c, out_c, kernal_size=(1,1), stride=(1,1))\n",
    "        self.relu = nn.LeakyReLU(0.2, inplace=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return self.relu(x)\n",
    "        \n",
    "class tRGB(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "        self.cvt = EqualizedLR_Conv2d(in_c, out_c, kernal_size=(1,1), stride=(1,1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return(self.cvt(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "44aa73ff-d1ff-4c88-8e29-a8891fb8628f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Discriminator block\n",
    "class D_Cell(nn.Module):\n",
    "    def __init__(self, in_c, out_c, sb=0):\n",
    "        self.sb = sb\n",
    "        super().__init__()\n",
    "        \n",
    "        #Define network structure\n",
    "        if sb == 1: #sb is your structure for the block\n",
    "            #Set structure\n",
    "            self.frgb = fRGB(in_c, out_c)\n",
    "            \n",
    "            self.econv1 = EqualizedLR_Conv2d(in_c, out_c, kernel_size=(3,3), stride=(1,1), padding=(1,1)) #Initial block a (alpha)\n",
    "            \n",
    "            self.econv2 = EqualizedLR_Conv2d(out_c, out_c, kernel_size=(4,4), stride=(1,1))\n",
    "            \n",
    "            self.outlayer = nn.AvgPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "        elif sb == 2:\n",
    "            self.ds = nn.AvgPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "            self.frgb = fRGB(in_c, out_c)                                                                 #initial block b (1-alpha)\n",
    "        elif sb == 0:\n",
    "            #Set normal cell structure\n",
    "            self.econv1 = EqualizedLR_Conv2d(in_c, out_c, kernel_size=(3,3), stride=(1,1), padding=(1,1)) #Initial block a (alpha)\n",
    "            \n",
    "            self.econv2 = EqualizedLR_Conv2d(out_c, out_c, kernel_size=(4,4), stride=(1,1))\n",
    "            \n",
    "            self.outlayer = nn.AvgPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "        else:\n",
    "            self.mbstd = Minibatch_std()\n",
    "            self.econv2 = EqualizedLR_Conv2d(out_c, out_c, kernel_size=(4,4), stride=(1,1)) #output block\n",
    "            self.finish = nn.Sequential(nn.Flatten(), nn.Linear(out_c, out_c) ,nn.LeakyReLU(0.2, inplace=True), nn.Linear(out_c, 1))\n",
    "        self.relu = nn.LeakyReLU(0.2, inplace=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        ### - Account for each discriminator block archetype - ###\n",
    "        if self.sb == 0 or self.sb == 1:\n",
    "            if self.sb == 1:\n",
    "                x = self.frgb(x)\n",
    "                x = self.relu(x)\n",
    "            x = self.econv1(x)\n",
    "            x = self.relu(x)\n",
    "            \n",
    "            x = self.econv(x)\n",
    "            x = self.relu(x)\n",
    "            \n",
    "            x = self.outlayer(x)\n",
    "        elif self.sb == 2:\n",
    "            x = self.ds(x)\n",
    "            x = self.frgb(x)\n",
    "            x = self.relu(x)\n",
    "        else:\n",
    "            x = self.mbstd(x)\n",
    "            x = self.econv2(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.finish(x)\n",
    "        return x\n",
    "            \n",
    "#Generator Block\n",
    "\n",
    "class G_Cell(nn.Module):\n",
    "    def __init__(self, in_c, out_c, sb=0):\n",
    "        self.sb = sb\n",
    "        super().__init__()\n",
    "        \n",
    "        #Define network structure\n",
    "        if sb == 0:\n",
    "            self.us = nn.Upsample(scale_factor=2, mode='nearest') #Base block (standard cell)\n",
    "            self.conv1 = EqualizedLR_Conv2d(in_c, out_c, kernel_size=(3,3), stride=(1,1), padding='same')\n",
    "            self.conv2 = EqualizedLR_Conv2d(in_c, out_c, kernel_size=(3,3), stride=(1,1), padding='same')\n",
    "        elif sb == 1:\n",
    "            self.dense = nn.Linear(in_c) #Our first initial training layer\n",
    "            self.conv1 = EqualizedLR_Conv2d(in_c, out_c, kernel_size=(3,3), stride=(1,1), padding='same')\n",
    "            \n",
    "        \n",
    "        self.relu = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.pn = Pixel_norm()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if self.sb == 0:\n",
    "            x = self.us(x)\n",
    "            x = self.conv1(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.pn(x)\n",
    "            x = self.conv2(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.pn(x)\n",
    "        elif self.sb == 1:\n",
    "            x = self.pn(x)\n",
    "            x = self.dense(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.pn(x)\n",
    "            x = self.conv1(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.pn(x)\n",
    "        return x\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7841ca2a-706f-4e35-baf0-81d62c76027b",
   "metadata": {},
   "source": [
    "# Network Structure and Basic Theory\n",
    "\n",
    "---\n",
    "\n",
    "Each network will progressively need to grow more and more in order to upscale the images while keeping each of the dims the same for upscaling it.\n",
    "Therefore to accurately train this model we construct it in such a way that we may output a 1 megapixel image.\n",
    "\n",
    "This involves defining the structure for the overall network once it is finished and including a depth index variable that will be increased in training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "11d1f096-8a71-462e-b687-261d3f8d0ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(3, 4, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (3): Conv2d(4, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "  (4): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#Discriminator#\n",
    "class G(nn.Module):\n",
    "    def __init__(self, ls, out):\n",
    "        \"\"\"\n",
    "        ls is latent size\n",
    "        out is desired output resolution\n",
    "        build structure iteratively\n",
    "        \"\"\"\n",
    "        super().__init()\n",
    "        self.depth = 1 #Current indexing\n",
    "        self.alpha = 1 #Fade value\n",
    "        self.incalpha = 0 #Value to increment alpha by\n",
    "        \n",
    "        self.trgb = tRGB(ls, 3) #torgb value\n",
    "        self.us = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        self.net = nn.ModuleList([G_Cell(ls, ls, sb=1)])\n",
    "        self.rgbs = nn.ModuleList([tRGB(latent_size, 3)])\n",
    "        \n",
    "        #Add all standard blocks\n",
    "        for i in range(2, int(np.log2(out))):\n",
    "            ### - trick is to decrease the latent vector as well for each of the higher level blocks - ###\n",
    "            if i < 7: \n",
    "                in_c = 1024\n",
    "                out_c = 1024\n",
    "            else:\n",
    "                in_c = int(1024 / 2**(i-7))\n",
    "                out_c = int(1024 / 2**(i-7))\n",
    "            self.net.append(G_Cell(in_c, out_c))\n",
    "            self.rgbs.append(tRGB(out_c, 3))\n",
    "            \n",
    "    def forward(self, x):\n",
    "        for cell in self.net[:self.depth-1]:\n",
    "            x = cell(x)\n",
    "        out = self.net[self.depth-1](x)\n",
    "        crgb = self.rgbs[self.depth-1](out)\n",
    "        if self.alpha < 1:\n",
    "            xprev = self.us(x)\n",
    "            rgbprev = self.rgbs[self.depth-2](xprev)\n",
    "            crgb = self.alpha * (rgbprev) + (1-self.alpha)*(crgb)\n",
    "        return crgb\n",
    "    def inc_depth(self, iters):\n",
    "        self.incalpha = 1/iters\n",
    "        self.alpha = 1/iters\n",
    "        self.depth += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "9a295f7e-fa06-44f3-8719-773833c3ea9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): ConvTranspose2d(100, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#Generator#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3cbe4a-830a-44ff-9275-6926a4ce0330",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
