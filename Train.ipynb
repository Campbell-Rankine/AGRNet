{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d215e447-f153-4454-9e74-0a6ed59bb15c",
   "metadata": {},
   "source": [
    " # Train file \n",
    " ---\n",
    " For the model we will start by showing that we can purely train on depths 1 and 2 as those are the first instances containing every possible block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d77657c6-ca7b-4210-89a3-022f21ed9609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\campb\\anaconda3\\lib\\site-packages\\torchvision\\io\\image.py:11: UserWarning: Failed to load image Python extension: Could not find module 'C:\\Users\\campb\\anaconda3\\Lib\\site-packages\\torchvision\\image.pyd' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "### - imports - ###\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2 as cv\n",
    "import os\n",
    "import random\n",
    "import argparse\n",
    "### - other data augmentation imports - ### (if needed)\n",
    "### - Imports - ###\n",
    "import math\n",
    "import numpy as np\n",
    "import sklearn as sk #general imports, initial data preprocessing/OS stuff\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import os\n",
    "import torch as T\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim #Neural network imports, multiply data etc\n",
    "from torchvision.transforms import ToTensor\n",
    "import torchvision.models as models\n",
    "import torchvision\n",
    "import torch.nn.functional as F #Neural Network used in Comp4660 at ANU\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler #normalize data\n",
    "from sklearn.metrics import confusion_matrix #analysis\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid, save_image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from NetworkMain import D, G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7179e90-3137-4cf6-9c6b-8e93fe29d356",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code will be added later when the file is converted to a python file\n",
    "\"\"\"parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--root', type=str, default='./', help='directory contrains the data and outputs')\n",
    "parser.add_argument('--epochs', type=int, default=40, help='training epoch number')\n",
    "parser.add_argument('--out_res', type=int, default=128, help='The resolution of final output image')\n",
    "parser.add_argument('--resume', type=int, default=0, help='continues from epoch number')\n",
    "parser.add_argument('--cuda', action='store_true', help='Using GPU to train')\n",
    "\n",
    "\n",
    "opt = parser.parse_args()\"\"\"\n",
    "\n",
    "root = '/Users/campb/Documents/PersonalProjects/AGRNet/'\n",
    "data_dir = root + 'Dataset/'\n",
    "check_point_dir = root + 'check_points/'\n",
    "output_dir = root + 'output/'\n",
    "weight_dir = root+ 'weight/'\n",
    "if not os.path.exists(check_point_dir):\n",
    "\tos.makedirs(check_point_dir)\n",
    "if not os.path.exists(output_dir):\n",
    "\tos.makedirs(output_dir)\n",
    "if not os.path.exists(weight_dir):\n",
    "\tos.makedirs(weight_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3f28971-e8b5-431e-93b8-d7e0dbbc57e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### - Global Variables - ###\n",
    "DFP = '/Users/campb/Documents/PersonalProjects/AGRNet/Dataset/Sample-'\n",
    "\n",
    "NS = '/Sample-'\n",
    "\n",
    "image_format = 'RGB'\n",
    "\n",
    "schedule = [[5, 15, 25 ,35, 40],[16, 16, 16, 8, 4],[5, 5, 5, 1, 1]] #Epochs for each cycle num of epochs\n",
    "\n",
    "batch_size = schedule[1][0]\n",
    "\n",
    "growing = schedule[2][0]\n",
    "\n",
    "epochs = 40\n",
    "\n",
    "latent_size = 1024\n",
    "\n",
    "out_res = 1024\n",
    "\n",
    "lr = 1e-4\n",
    "\n",
    "lambd = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b0cca62-5f79-4e2b-88a4-cbe713331853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = T.device('cuda:0' if (T.cuda.is_available())  else 'cpu')\n",
    "\n",
    "transform = transforms.Compose([\n",
    "            transforms.Resize(out_res),\n",
    "            transforms.CenterCrop(out_res),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "            ])\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab319914-ad8f-4e7d-8277-2c86846b1ba9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'latent_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21276/2699848587.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mGen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mDisc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlatent_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_res\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mGen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mG\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlatent_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_res\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\PersonalProjects\\AGRNet\\NetworkMain.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, ls, out)\u001b[0m\n\u001b[0;32m    197\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUpsample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscale_factor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'nearest'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModuleList\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mG_Cell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrgbs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModuleList\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtRGB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlatent_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m         \u001b[1;31m#Add all standard blocks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'latent_size' is not defined"
     ]
    }
   ],
   "source": [
    "#Create networks\n",
    "Disc = None\n",
    "Gen = None\n",
    "Disc = D(latent_size, out_res).to(device)\n",
    "Gen = G(latent_size, out_res).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b42f5d-48e8-4639-9185-8fd1359519ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
