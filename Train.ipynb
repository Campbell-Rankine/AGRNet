{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d215e447-f153-4454-9e74-0a6ed59bb15c",
   "metadata": {},
   "source": [
    " # Train file \n",
    " ---\n",
    " For the model we will start by showing that we can purely train on depths 1 and 2 as those are the first instances containing every possible block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d77657c6-ca7b-4210-89a3-022f21ed9609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\campb\\anaconda3\\lib\\site-packages\\torchvision\\io\\image.py:11: UserWarning: Failed to load image Python extension: Could not find module 'C:\\Users\\campb\\anaconda3\\Lib\\site-packages\\torchvision\\image.pyd' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "### - imports - ###\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2 as cv\n",
    "import os\n",
    "import random\n",
    "import argparse\n",
    "### - other data augmentation imports - ### (if needed)\n",
    "### - Imports - ###\n",
    "import math\n",
    "import numpy as np\n",
    "import sklearn as sk #general imports, initial data preprocessing/OS stuff\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import os\n",
    "import torch as T\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim #Neural network imports, multiply data etc\n",
    "from torchvision.transforms import ToTensor\n",
    "import torchvision.models as models\n",
    "import torchvision\n",
    "import torch.nn.functional as F #Neural Network used in Comp4660 at ANU\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler #normalize data\n",
    "from sklearn.metrics import confusion_matrix #analysis\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid, save_image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    "from NetworkMain import D, G\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7179e90-3137-4cf6-9c6b-8e93fe29d356",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code will be added later when the file is converted to a python file\n",
    "\"\"\"parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--root', type=str, default='./', help='directory contrains the data and outputs')\n",
    "parser.add_argument('--epochs', type=int, default=40, help='training epoch number')\n",
    "parser.add_argument('--out_res', type=int, default=128, help='The resolution of final output image')\n",
    "parser.add_argument('--resume', type=int, default=0, help='continues from epoch number')\n",
    "parser.add_argument('--cuda', action='store_true', help='Using GPU to train')\n",
    "\n",
    "\n",
    "opt = parser.parse_args()\"\"\"\n",
    "\n",
    "root = '/Users/campb/Documents/PersonalProjects/AGRNet/'\n",
    "data_dir = root + 'Dataset/'\n",
    "check_point_dir = root + 'check_points/'\n",
    "output_dir = root + 'output/'\n",
    "weight_dir = root+ 'weight/'\n",
    "if not os.path.exists(check_point_dir):\n",
    "\tos.makedirs(check_point_dir)\n",
    "if not os.path.exists(output_dir):\n",
    "\tos.makedirs(output_dir)\n",
    "if not os.path.exists(weight_dir):\n",
    "\tos.makedirs(weight_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3f28971-e8b5-431e-93b8-d7e0dbbc57e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### - Global Variables - ###\n",
    "DFP = '/Users/campb/Documents/PersonalProjects/AGRNet/Dataset/Sample-'\n",
    "\n",
    "img_folder = '/Users/campb/Documents/PersonalProjects/AGRNet/Dataset/'\n",
    "\n",
    "NS = '/Sample-'\n",
    "\n",
    "image_format = 'RGB'\n",
    "\n",
    "schedule = [[5, 15, 25 ,35, 40],[16, 16, 16, 8, 4],[5, 5, 5, 1, 1]] #Epochs for each cycle num of epochs\n",
    "\n",
    "batch_size = schedule[1][0]\n",
    "\n",
    "growing = schedule[2][0]\n",
    "\n",
    "epochs = 40\n",
    "\n",
    "latent_size = 512\n",
    "\n",
    "out_res = 1024\n",
    "\n",
    "lr = 1e-4\n",
    "\n",
    "lambd = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b0cca62-5f79-4e2b-88a4-cbe713331853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = T.device('cuda:0' if (T.cuda.is_available())  else 'cpu')\n",
    "\n",
    "transform = transforms.Compose([\n",
    "            transforms.Resize(out_res),\n",
    "            transforms.CenterCrop(out_res),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "            ])\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab319914-ad8f-4e7d-8277-2c86846b1ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create networks\n",
    "Disc = None\n",
    "Gen = None\n",
    "Disc = D(latent_size, out_res).to(device)\n",
    "Gen = G(latent_size, out_res).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43b42f5d-48e8-4639-9185-8fd1359519ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Noise for discriminator\n",
    "fixed_noise = T.randn(16, latent_size, 1, 1, device=device)\n",
    "#initialize optimizers\n",
    "D_optimizer = optim.Adam(Disc.parameters(), lr=lr, betas=(0, 0.99))\n",
    "G_optimizer = optim.Adam(Gen.parameters(), lr=lr, betas=(0, 0.99))\n",
    "#Metric variables\n",
    "D_running_loss = 0.0\n",
    "G_running_loss = 0.0\n",
    "iter_num = 0\n",
    "\n",
    "D_epoch_losses = []\n",
    "G_epoch_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31937179-b410-4458-a030-578806d24dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load with ImageFolder wrapper\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self,img_folder,names, transform):\n",
    "        self.transform = transform\n",
    "        self.image_names = names #Predetermined dataset\n",
    "        self.img_folder=img_folder\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_names)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        image=Image.open(self.img_folder+self.image_names[index]).convert(\"RGB\")\n",
    "        image=self.transform(image)\n",
    "        return image\n",
    "\n",
    "assert(os.path.exists(DFP + str(1) + \".jpg\"))\n",
    "rawimgf = sorted(glob.glob(DFP + '*.jpg', recursive = True))\n",
    "### - image names - ###\n",
    "imnames = [i.split('/')[-1].split(\"t\")[-1][1:] for i in rawimgf]\n",
    "\n",
    "### - Global data loader Vars - ###\n",
    "norms = (0.,0.,0.), (1.0,1.0,1.0)\n",
    "train_transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Resize((out_res, out_res))])\n",
    "# Parameters\n",
    "params = {'batch_size': schedule[1][0],\n",
    "          'shuffle': True,\n",
    "         'num_workers': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "374fa1ea-fc48-4646-83ff-53d980ec488a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nexcept:\\n    print('Fully Grown\\n')\\n    c = -1\\n    batch_size = schedule[1][c]\\n    growing = schedule[2][c]\\n\\n    dataset = ImageDataset(img_folder,imnames, train_transform)\\n    data_loader = DataLoader(dataset, **params)\\n\\n    tot_iter_num = (len(dataset)/batch_size)\\n    print(schedule[0][c], resume)\\n\\n    if Gen.alpha < 1:\\n        Gen.fade_iters = (1-Gen.alpha)/(opt.epochs-opt.resume)/(2*tot_iter_num)\\n        Ddisc.fade_iters = (1-Disc.alpha)/(opt.epochs-opt.resume)/(2*tot_iter_num)\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Control variable\n",
    "resume = 0\n",
    "if resume != 0:\n",
    "    check_point = T.load(check_point_dir+'check_point_epoch_%i.pth' % resume)\n",
    "    fixed_noise = check_point['fixed_noise']\n",
    "    G_net.load_state_dict(check_point['G_net'])\n",
    "    D_net.load_state_dict(check_point['D_net'])\n",
    "    G_optimizer.load_state_dict(check_point['G_optimizer'])\n",
    "    D_optimizer.load_state_dict(check_point['D_optimizer'])\n",
    "    G_epoch_losses = check_point['G_epoch_losses']\n",
    "    D_epoch_losses = check_point['D_epoch_losses']\n",
    "    G_net.depth = check_point['depth']\n",
    "    D_net.depth = check_point['depth']\n",
    "    G_net.alpha = check_point['alpha']\n",
    "    D_net.alpha = check_point['alpha']\n",
    "\n",
    "\n",
    "\n",
    "c = next(x[0] for x in enumerate(schedule[0]) if x[1]>resume)-1\n",
    "batch_size = schedule[1][c]\n",
    "growing = schedule[2][c]\n",
    "dataset = ImageDataset(img_folder, imnames, train_transform)\n",
    "# dataset = datasets.CelebA(data_dir, split='all', transform=transform)\n",
    "data_loader = DataLoader(dataset, **params)\n",
    "\n",
    "tot_iter_num = (len(dataset)/batch_size)\n",
    "Gen.fade_iters = (1-Gen.alpha)/(schedule[0][c+1]-resume)/(2*tot_iter_num)\n",
    "Disc.fade_iters = (1-Disc.alpha)/(schedule[0][c+1]-resume)/(2*tot_iter_num)\n",
    "\n",
    "\"\"\"\n",
    "except:\n",
    "    print('Fully Grown\\n')\n",
    "    c = -1\n",
    "    batch_size = schedule[1][c]\n",
    "    growing = schedule[2][c]\n",
    "\n",
    "    dataset = ImageDataset(img_folder,imnames, train_transform)\n",
    "    data_loader = DataLoader(dataset, **params)\n",
    "\n",
    "    tot_iter_num = (len(dataset)/batch_size)\n",
    "    print(schedule[0][c], resume)\n",
    "\n",
    "    if Gen.alpha < 1:\n",
    "        Gen.fade_iters = (1-Gen.alpha)/(opt.epochs-opt.resume)/(2*tot_iter_num)\n",
    "        Ddisc.fade_iters = (1-Disc.alpha)/(opt.epochs-opt.resume)/(2*tot_iter_num)\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f11a8ab5-7099-4387-aa96-99c383b799f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Resolution: 4 x 4\n",
      "epoch: 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 8192])\n",
      "torch.Size([16, 8192])\n",
      "torch.Size([16, 3, 4, 4])\n",
      "torch.Size([16, 8192])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D_loss: 2.443   G_loss: 0.003:   9%|████▋                                               | 1/11 [00:01<00:13,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 8192])\n",
      "iteration : 0, gp: 2.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D_loss: 2.443   G_loss: 0.003:  18%|█████████▍                                          | 2/11 [00:01<00:07,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 8192])\n",
      "torch.Size([16, 8192])\n",
      "torch.Size([16, 3, 4, 4])\n",
      "torch.Size([16, 8192])\n",
      "torch.Size([16, 8192])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D_loss: 2.443   G_loss: 0.003:  27%|██████████████▏                                     | 3/11 [00:02<00:05,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 8192])\n",
      "torch.Size([16, 8192])\n",
      "torch.Size([16, 3, 4, 4])\n",
      "torch.Size([16, 8192])\n",
      "torch.Size([16, 8192])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D_loss: 2.443   G_loss: 0.003:  36%|██████████████████▉                                 | 4/11 [00:02<00:03,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 8192])\n",
      "torch.Size([16, 8192])\n",
      "torch.Size([16, 3, 4, 4])\n",
      "torch.Size([16, 8192])\n",
      "torch.Size([16, 8192])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D_loss: 2.443   G_loss: 0.003:  45%|███████████████████████▋                            | 5/11 [00:03<00:02,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 8192])\n",
      "torch.Size([16, 8192])\n",
      "torch.Size([16, 3, 4, 4])\n",
      "torch.Size([16, 8192])\n",
      "torch.Size([16, 8192])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D_loss: 2.443   G_loss: 0.003:  55%|████████████████████████████▎                       | 6/11 [00:03<00:02,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 8192])\n",
      "torch.Size([16, 8192])\n",
      "torch.Size([16, 3, 4, 4])\n",
      "torch.Size([16, 8192])\n",
      "torch.Size([16, 8192])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D_loss: 2.443   G_loss: 0.003:  64%|█████████████████████████████████                   | 7/11 [00:03<00:01,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 8192])\n",
      "torch.Size([16, 8192])\n",
      "torch.Size([16, 3, 4, 4])\n",
      "torch.Size([16, 8192])\n",
      "torch.Size([16, 8192])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D_loss: 2.443   G_loss: 0.003:  73%|█████████████████████████████████████▊              | 8/11 [00:04<00:01,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 8192])\n",
      "torch.Size([16, 8192])\n",
      "torch.Size([16, 3, 4, 4])\n",
      "torch.Size([16, 8192])\n",
      "torch.Size([16, 8192])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D_loss: 2.443   G_loss: 0.003:  82%|██████████████████████████████████████████▌         | 9/11 [00:04<00:00,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 8192])\n",
      "torch.Size([16, 8192])\n",
      "torch.Size([16, 3, 4, 4])\n",
      "torch.Size([16, 8192])\n",
      "torch.Size([16, 8192])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D_loss: 2.443   G_loss: 0.003: 100%|███████████████████████████████████████████████████| 11/11 [00:05<00:00,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 8192])\n",
      "torch.Size([16, 8192])\n",
      "torch.Size([16, 3, 4, 4])\n",
      "torch.Size([16, 8192])\n",
      "torch.Size([16, 8192])\n",
      "torch.Size([1, 8192])\n",
      "torch.Size([1, 8192])\n",
      "torch.Size([1, 3, 4, 4])\n",
      "torch.Size([1, 8192])\n",
      "torch.Size([1, 8192])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D_loss: nan   G_loss: nan:   9%|█████                                                   | 1/11 [00:00<00:04,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 8192])\n",
      "torch.Size([16, 8192])\n",
      "torch.Size([16, 3, 4, 4])\n",
      "torch.Size([16, 8192])\n",
      "torch.Size([16, 8192])\n",
      "iteration : 0, gp: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D_loss: nan   G_loss: nan:  18%|██████████▏                                             | 2/11 [00:00<00:03,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 8192])\n",
      "torch.Size([16, 8192])\n",
      "torch.Size([16, 3, 4, 4])\n",
      "torch.Size([16, 8192])\n",
      "torch.Size([16, 8192])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D_loss: nan   G_loss: nan:  27%|███████████████▎                                        | 3/11 [00:01<00:03,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 8192])\n",
      "torch.Size([16, 8192])\n",
      "torch.Size([16, 3, 4, 4])\n",
      "torch.Size([16, 8192])\n",
      "torch.Size([16, 8192])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D_loss: nan   G_loss: nan:  36%|████████████████████▎                                   | 4/11 [00:01<00:02,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 8192])\n",
      "torch.Size([16, 8192])\n",
      "torch.Size([16, 3, 4, 4])\n",
      "torch.Size([16, 8192])\n",
      "torch.Size([16, 8192])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D_loss: nan   G_loss: nan:  45%|█████████████████████████▍                              | 5/11 [00:02<00:02,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 8192])\n",
      "torch.Size([16, 8192])\n",
      "torch.Size([16, 3, 4, 4])\n",
      "torch.Size([16, 8192])\n",
      "torch.Size([16, 8192])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D_loss: nan   G_loss: nan:  55%|██████████████████████████████▌                         | 6/11 [00:02<00:02,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 8192])\n",
      "torch.Size([16, 8192])\n",
      "torch.Size([16, 3, 4, 4])\n",
      "torch.Size([16, 8192])\n",
      "torch.Size([16, 8192])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D_loss: nan   G_loss: nan:  64%|███████████████████████████████████▋                    | 7/11 [00:02<00:01,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 8192])\n",
      "torch.Size([16, 8192])\n",
      "torch.Size([16, 3, 4, 4])\n",
      "torch.Size([16, 8192])\n",
      "torch.Size([16, 8192])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D_loss: nan   G_loss: nan:  73%|████████████████████████████████████████▋               | 8/11 [00:03<00:01,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 8192])\n",
      "torch.Size([16, 8192])\n",
      "torch.Size([16, 3, 4, 4])\n",
      "torch.Size([16, 8192])\n",
      "torch.Size([16, 8192])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D_loss: nan   G_loss: nan:  82%|█████████████████████████████████████████████▊          | 9/11 [00:03<00:00,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 8192])\n",
      "torch.Size([16, 8192])\n",
      "torch.Size([16, 3, 4, 4])\n",
      "torch.Size([16, 8192])\n",
      "torch.Size([16, 8192])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D_loss: nan   G_loss: nan: 100%|███████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 8192])\n",
      "torch.Size([16, 8192])\n",
      "torch.Size([16, 3, 4, 4])\n",
      "torch.Size([16, 8192])\n",
      "torch.Size([16, 8192])\n",
      "torch.Size([1, 8192])\n",
      "torch.Size([1, 8192])\n",
      "torch.Size([1, 3, 4, 4])\n",
      "torch.Size([1, 8192])\n",
      "torch.Size([1, 8192])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at ..\\caffe2\\serialize\\inline_container.cc:300] . unexpected pos 245196288 vs 245196176",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[0;32m    378\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 379\u001b[1;33m                 \u001b[0m_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    380\u001b[0m                 \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_save\u001b[1;34m(obj, zip_file, pickle_module, pickle_protocol)\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[0mnum_bytes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstorage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mstorage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0melement_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m         \u001b[0mzip_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_record\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_ptr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_bytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    500\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11892/437430086.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[0mGen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m         \u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheck_point\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_point_dir\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'check_point_epoch_%d.pth'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m         \u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight_dir\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'G_weight_epoch_%d.pth'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m         \u001b[0mout_imgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfixed_noise\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[0;32m    378\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m                 \u001b[0m_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 380\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    381\u001b[0m         \u001b[0m_legacy_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 259\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_end_of_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    260\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at ..\\caffe2\\serialize\\inline_container.cc:300] . unexpected pos 245196288 vs 245196176"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### - Train Loop - ###\n",
    "size = 2**(Gen.depth+1)\n",
    "print(\"Output Resolution: %d x %d\" % (size, size))\n",
    "for epoch in range(1+resume, epochs+1):\n",
    "    Gen.train()\n",
    "    D_epoch_loss = 0.0\n",
    "    G_epoch_loss = 0.0\n",
    "    if epoch-1 in schedule[0]:\n",
    "\n",
    "        if (2 **(Gen.depth +1) < out_res):\n",
    "            c = schedule[0].index(epoch-1)\n",
    "            batch_size = schedule[1][c]\n",
    "            growing = schedule[2][0]\n",
    "            data_loader = DataLoader(dataset, **params)\n",
    "            tot_iter_num = tot_iter_num = (len(dataset)/batch_size)\n",
    "            Gen.growing_net(growing*tot_iter_num)\n",
    "            Disc.growing_net(growing*tot_iter_num)\n",
    "            size = 2**(Gen.depth+1)\n",
    "            print(\"Output Resolution: %d x %d\" % (size, size))\n",
    "\n",
    "\t\n",
    "    print(\"epoch: %i/%i\" % (int(epoch), int(epochs)))\n",
    "    databar = tqdm(data_loader)\n",
    "    for i, samples in enumerate(databar):\n",
    "        ##  update D\n",
    "        if size != out_res: #Basically need to, A Reshape, B prepare the data for the networks\n",
    "            samples = F.interpolate(samples, size=(size,size)).to(device)\n",
    "        else:\n",
    "            samples = samples.to(device)\n",
    "        Disc.zero_grad()\n",
    "        noise = T.randn(samples.size(0), latent_size, 1, 1, device=device)\n",
    "        fake = Gen(noise)\n",
    "        out_grid = make_grid(fake, normalize=True, nrow=4, scale_each=True, padding=int(0.5*(2**Gen.depth))).permute(1,2,0)\n",
    "        plt.imshow(out_grid.cpu())\n",
    "        fake_out = Disc(fake.detach())\n",
    "        real_out = Disc(samples)\n",
    "        ## Gradient Penalty\n",
    "        \n",
    "        eps = T.rand(samples.size(0), 1, 1, 1, device=device)\n",
    "        eps = eps.expand_as(Gen(noise))\n",
    "        x_hat = eps * samples + (1 - eps) * fake.detach()\n",
    "        x_hat.requires_grad = True\n",
    "        print(x_hat.shape)\n",
    "        px_hat = Disc(x_hat)\n",
    "        grad = T.autograd.grad(\n",
    "                                    outputs = px_hat.sum(),\n",
    "                                    inputs = x_hat, \n",
    "                                    create_graph=True\n",
    "                                    )[0]\n",
    "        grad_norm = grad.view(samples.size(0), -1).norm(2, dim=1)\n",
    "        gradient_penalty = lambd * ((grad_norm  - 1)**2).mean()\n",
    "\n",
    "        ###########\n",
    "\n",
    "        D_loss = fake_out.mean() - real_out.mean() + gradient_penalty\n",
    "\n",
    "        D_loss.backward()\n",
    "        D_optimizer.step()\n",
    "\n",
    "        ##\tupdate G\n",
    "\n",
    "        Gen.zero_grad()\n",
    "        fake_out = Disc(fake)\n",
    "\n",
    "        G_loss = - fake_out.mean()\n",
    "\n",
    "        G_loss.backward()\n",
    "        G_optimizer.step()\n",
    "\n",
    "        ##############\n",
    "\n",
    "        D_running_loss += D_loss.item()\n",
    "        G_running_loss += G_loss.item()\n",
    "\n",
    "        iter_num += 1\n",
    "\n",
    "\n",
    "        if i % 500== 0:\n",
    "            D_running_loss /= iter_num\n",
    "            G_running_loss /= iter_num\n",
    "            print('iteration : %d, gp: %.2f' % (i, gradient_penalty))\n",
    "            databar.set_description('D_loss: %.3f   G_loss: %.3f' % (D_running_loss ,G_running_loss))\n",
    "            iter_num = 0\n",
    "            D_running_loss = 0.0\n",
    "            G_running_loss = 0.0\n",
    "\n",
    "\n",
    "    D_epoch_losses.append(D_epoch_loss/tot_iter_num)\n",
    "    G_epoch_losses.append(G_epoch_loss/tot_iter_num)\n",
    "\n",
    "\n",
    "    check_point = {'G_net' : Gen.state_dict(), \n",
    "                   'G_optimizer' : G_optimizer.state_dict(),\n",
    "                   'D_net' : Disc.state_dict(),\n",
    "                   'D_optimizer' : D_optimizer.state_dict(),\n",
    "                   'D_epoch_losses' : D_epoch_losses,\n",
    "                   'G_epoch_losses' : G_epoch_losses,\n",
    "                   'fixed_noise': fixed_noise,\n",
    "                   'depth': Gen.depth,\n",
    "                   'alpha':Gen.alpha\n",
    "                   }\n",
    "    with T.no_grad():\n",
    "        Gen.eval()\n",
    "        T.save(check_point, check_point_dir + 'check_point_epoch_%d.pth' % (epoch))\n",
    "        T.save(Gen.state_dict(), weight_dir + 'G_weight_epoch_%d.pth' %(epoch))\n",
    "        out_imgs = Gen(fixed_noise)\n",
    "        out_grid = make_grid(out_imgs, normalize=True, nrow=4, scale_each=True, padding=int(0.5*(2**Gen.depth))).permute(1,2,0)\n",
    "        plt.imshow(out_grid.cpu())\n",
    "        plt.savefig(output_dir + 'size_%i_epoch_%d' %(size ,epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02407ee-e17b-438e-80a6-32a0a18126d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd26dfe1-028f-43d6-8ec6-950001e1f936",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
