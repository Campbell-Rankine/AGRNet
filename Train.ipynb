{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d215e447-f153-4454-9e74-0a6ed59bb15c",
   "metadata": {},
   "source": [
    " # Train file \n",
    " ---\n",
    " For the model we will start by showing that we can purely train on depths 1 and 2 as those are the first instances containing every possible block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3f27e1-e8ec-4db0-b2a2-d7ffc4b8b776",
   "metadata": {},
   "source": [
    "## Shift in the overall goal of this project:\n",
    "---\n",
    "Originally this project started with the goal to combine two networks together to create stereoscopic images based on surrealist art. However, this process, while definitely possible through sets of linear translations and object degmentation, is impractical for real runtime arguments. So here in the notebooks we provide a proof of concept for the network, however we will be turning this into a script for the Blender and Maxwell tools for 3-D modelling\n",
    "\n",
    "Blender: Construct a 3D set of objects in a constrained 3-D domain\n",
    "Maxwell: Render these objects\n",
    "\n",
    "For now we will focus on a proof of concept ProGAN, and from there we repurpose this gan for our script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d77657c6-ca7b-4210-89a3-022f21ed9609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\campb\\anaconda3\\lib\\site-packages\\torchvision\\io\\image.py:11: UserWarning: Failed to load image Python extension: Could not find module 'C:\\Users\\campb\\anaconda3\\Lib\\site-packages\\torchvision\\image.pyd' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "### - imports - ###\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2 as cv\n",
    "import os\n",
    "import random\n",
    "import argparse\n",
    "### - other data augmentation imports - ### (if needed)\n",
    "### - Imports - ###\n",
    "import math\n",
    "import numpy as np\n",
    "import sklearn as sk #general imports, initial data preprocessing/OS stuff\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import os\n",
    "import torch as T\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim #Neural network imports, multiply data etc\n",
    "from torchvision.transforms import ToTensor\n",
    "import torchvision.models as models\n",
    "import torchvision\n",
    "import torch.nn.functional as F #Neural Network used in Comp4660 at ANU\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler #normalize data\n",
    "from sklearn.metrics import confusion_matrix #analysis\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid, save_image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    "from NetworkMain import D, G\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7179e90-3137-4cf6-9c6b-8e93fe29d356",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code will be added later when the file is converted to a python file\n",
    "\"\"\"parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--root', type=str, default='./', help='directory contrains the data and outputs')\n",
    "parser.add_argument('--epochs', type=int, default=40, help='training epoch number')\n",
    "parser.add_argument('--out_res', type=int, default=128, help='The resolution of final output image')\n",
    "parser.add_argument('--resume', type=int, default=0, help='continues from epoch number')\n",
    "parser.add_argument('--cuda', action='store_true', help='Using GPU to train')\n",
    "\n",
    "\n",
    "opt = parser.parse_args()\"\"\"\n",
    "\n",
    "root = '/Users/campb/Documents/PersonalProjects/AGRNet/'\n",
    "data_dir = root + 'Dataset/'\n",
    "check_point_dir = root + 'check_points/'\n",
    "output_dir = root + 'output/'\n",
    "weight_dir = root+ 'weight/'\n",
    "if not os.path.exists(check_point_dir):\n",
    "\tos.makedirs(check_point_dir)\n",
    "if not os.path.exists(output_dir):\n",
    "\tos.makedirs(output_dir)\n",
    "if not os.path.exists(weight_dir):\n",
    "\tos.makedirs(weight_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3f28971-e8b5-431e-93b8-d7e0dbbc57e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### - Global Variables - ###\n",
    "DFP = '/Users/campb/Documents/PersonalProjects/AGRNet/Dataset/Sample-'\n",
    "\n",
    "img_folder = '/Users/campb/Documents/PersonalProjects/AGRNet/Dataset/'\n",
    "\n",
    "NS = '/Sample-'\n",
    "\n",
    "image_format = 'RGB'\n",
    "\n",
    "schedule = [[5, 15, 25 ,35, 40],[3, 5, 5, 5, 4],[5, 5, 5, 1, 1]] #Epochs for each cycle num of epochs\n",
    "\n",
    "batch_size = schedule[1][0]\n",
    "\n",
    "growing = schedule[2][0]\n",
    "\n",
    "epochs = 70\n",
    "\n",
    "latent_size = 512\n",
    "\n",
    "out_res = 1024\n",
    "\n",
    "lr = 1e-5\n",
    "\n",
    "lambd = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b0cca62-5f79-4e2b-88a4-cbe713331853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = T.device('cuda:0' if (T.cuda.is_available())  else 'cpu')\n",
    "\n",
    "transform = transforms.Compose([\n",
    "            transforms.Resize(out_res),\n",
    "            transforms.RandomCrop(out_res, 4),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "            ])\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab319914-ad8f-4e7d-8277-2c86846b1ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create networks\n",
    "Disc = None\n",
    "Gen = None\n",
    "Disc = D(latent_size, out_res).to(device)\n",
    "Gen = G(latent_size, out_res).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43b42f5d-48e8-4639-9185-8fd1359519ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Noise for discriminator\n",
    "fixed_noise = T.randn(16, latent_size, 1, 1).to(device)\n",
    "#initialize optimizers\n",
    "D_optimizer = optim.Adam(Disc.parameters(), lr=lr, betas=(0, 0.99))\n",
    "G_optimizer = optim.Adam(Gen.parameters(), lr=lr, betas=(0, 0.99))\n",
    "#Metric variables\n",
    "D_running_loss = 0.0\n",
    "G_running_loss = 0.0\n",
    "iter_num = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31937179-b410-4458-a030-578806d24dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load with ImageFolder wrapper\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self,img_folder,names, transform):\n",
    "        self.transform = transform\n",
    "        self.image_names = names #Predetermined dataset\n",
    "        self.img_folder=img_folder\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_names)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        image=Image.open(self.img_folder+self.image_names[index]).convert(\"RGB\")\n",
    "        image=self.transform(image)\n",
    "        return image\n",
    "\n",
    "assert(os.path.exists(DFP + str(1) + \".jpg\"))\n",
    "rawimgf = sorted(glob.glob(DFP + '*.jpg', recursive = True))\n",
    "### - image names - ###\n",
    "imnames = [i.split('/')[-1].split(\"t\")[-1][1:] for i in rawimgf]\n",
    "\n",
    "### - Global data loader Vars - ###\n",
    "norms = (0.5,0.5,0.5), (0.5,0.5,0.5)\n",
    "train_transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Resize((out_res, out_res))])\n",
    "# Parameters\n",
    "params = {'batch_size': schedule[1][0],\n",
    "          'shuffle': True,\n",
    "         'num_workers': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "374fa1ea-fc48-4646-83ff-53d980ec488a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nexcept:\\n    print('Fully Grown\\n')\\n    c = -1\\n    batch_size = schedule[1][c]\\n    growing = schedule[2][c]\\n\\n    dataset = ImageDataset(img_folder,imnames, train_transform)\\n    data_loader = DataLoader(dataset, **params)\\n\\n    tot_iter_num = (len(dataset)/batch_size)\\n    print(schedule[0][c], resume)\\n\\n    if Gen.alpha < 1:\\n        Gen.fade_iters = (1-Gen.alpha)/(opt.epochs-opt.resume)/(2*tot_iter_num)\\n        Ddisc.fade_iters = (1-Disc.alpha)/(opt.epochs-opt.resume)/(2*tot_iter_num)\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Control variable\n",
    "resume = 0\n",
    "if resume != 0:\n",
    "    check_point = T.load(check_point_dir+'check_point_epoch_%i.pth' % resume)\n",
    "    fixed_noise = check_point['fixed_noise']\n",
    "    G_net.load_state_dict(check_point['G_net'])\n",
    "    D_net.load_state_dict(check_point['D_net'])\n",
    "    G_optimizer.load_state_dict(check_point['G_optimizer'])\n",
    "    D_optimizer.load_state_dict(check_point['D_optimizer'])\n",
    "    G_epoch_losses = check_point['G_epoch_losses']\n",
    "    D_epoch_losses = check_point['D_epoch_losses']\n",
    "    G_net.depth = check_point['depth']\n",
    "    D_net.depth = check_point['depth']\n",
    "    G_net.alpha = check_point['alpha']\n",
    "    D_net.alpha = check_point['alpha']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "except:\n",
    "    print('Fully Grown\\n')\n",
    "    c = -1\n",
    "    batch_size = schedule[1][c]\n",
    "    growing = schedule[2][c]\n",
    "\n",
    "    dataset = ImageDataset(img_folder,imnames, train_transform)\n",
    "    data_loader = DataLoader(dataset, **params)\n",
    "\n",
    "    tot_iter_num = (len(dataset)/batch_size)\n",
    "    print(schedule[0][c], resume)\n",
    "\n",
    "    if Gen.alpha < 1:\n",
    "        Gen.fade_iters = (1-Gen.alpha)/(opt.epochs-opt.resume)/(2*tot_iter_num)\n",
    "        Ddisc.fade_iters = (1-Disc.alpha)/(opt.epochs-opt.resume)/(2*tot_iter_num)\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201177e9-1af8-463d-91ca-2a19e4a1b6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training current depth 1 at size: 4 x 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0.000 D_loss: 0.150   G_loss: 0.143: 100%|██████████████████████████████████████| 54/54 [00:08<00:00,  6.36it/s]\n",
      "Epoch: 1.000 D_loss: 0.418   G_loss: 0.147:  13%|█████                                  | 7/54 [00:00<00:05,  9.03it/s]"
     ]
    }
   ],
   "source": [
    "#Implement a different train loop that allows us to train the network on some data\n",
    "#Depth -> Epochs -> samples for 9 total training cycles\n",
    "schedule = [[10, 12, 16, 20, 24, 28, 32, 64, 70], #Epochs for each depth\n",
    "            [12, 12, 6, 3, 3, 3, 2, 2, 2]] #Batch Size (Has to decrease to conserve memory)\n",
    "dataset = ImageDataset(img_folder, imnames, train_transform)\n",
    "# dataset = datasets.CelebA(data_dir, split='all', transform=transform)\n",
    "data_loader = DataLoader(dataset, **params)\n",
    "\n",
    "inc = 0\n",
    "epoch_ = schedule[0][inc] #Increment \n",
    "batch_s_ = schedule[1][inc]\n",
    "tot_iter_num = (len(dataset)/batch_size)\n",
    "Gen.fade_iters = (1-Gen.alpha)/(schedule[0][inc])/(2*tot_iter_num)\n",
    "Disc.fade_iters = (1-Disc.alpha)/(schedule[0][inc])/(2*tot_iter_num)\n",
    "\n",
    "depth_losses_g = []\n",
    "depth_losses_d = []\n",
    "\n",
    "for depth in range(1, int(np.log2(out_res))):\n",
    "    Gen.train()\n",
    "    size = 2**(Gen.depth+1)\n",
    "    print(\"Training current depth %d at size: %i x %i\" % (depth, size, size))\n",
    "    Depth_loss_g = 0.0\n",
    "    Depth_loss_d = 0.0\n",
    "    #Epochs\n",
    "    epoch_ = schedule[0][inc] #save increment epoch and batch size\n",
    "    batch_s_ = schedule[1][inc]\n",
    "    D_epoch_losses = []\n",
    "    G_epoch_losses = []\n",
    "    for epoch in range(epoch_):\n",
    "        D_epoch_loss = 0.0\n",
    "        G_epoch_loss = 0.0\n",
    "\n",
    "        databar = tqdm(data_loader)\n",
    "        for i, samples in enumerate(databar):\n",
    "            ##  update D\n",
    "            if size != out_res: #Basically need to, A Reshape, B prepare the data for the networks\n",
    "                samples = F.interpolate(samples, size=(size,size)).to(device)\n",
    "            else:\n",
    "                samples = samples.to(device)\n",
    "            Disc.zero_grad()\n",
    "            noise = T.randn(samples.size(0), latent_size, 1, 1, device=device)\n",
    "            fake = Gen(noise)\n",
    "            #out_grid = make_grid(fake, normalize=True, nrow=4, scale_each=True, padding=int(0.5*(2**Gen.depth))).permute(1,2,0)\n",
    "            #plt.imshow(out_grid.cpu())\n",
    "            fake_out = Disc(fake.detach())\n",
    "            real_out = Disc(samples)\n",
    "            ## Gradient Penalty\n",
    "\n",
    "            eps = T.rand(samples.size(0), 1, 1, 1, device=device)\n",
    "            eps = eps.expand_as(Gen(noise))\n",
    "            x_hat = eps * samples + (1 - eps) * fake.detach()\n",
    "            x_hat.requires_grad = True\n",
    "            px_hat = Disc(x_hat)\n",
    "            grad = T.autograd.grad(\n",
    "                                        outputs = px_hat.sum(),\n",
    "                                        inputs = x_hat, \n",
    "                                        create_graph=True\n",
    "                                        )[0]\n",
    "            grad_norm = grad.view(samples.size(0), -1).norm(2, dim=1)\n",
    "            gradient_penalty = lambd * ((grad_norm  - 1)**2).mean()\n",
    "            ###########\n",
    "\n",
    "            D_loss = fake_out.mean() - real_out.mean() + gradient_penalty\n",
    "            D_loss.backward()\n",
    "            D_optimizer.step()\n",
    "\n",
    "            ##\tupdate G\n",
    "\n",
    "            Gen.zero_grad()\n",
    "            fake_out = Disc(fake)\n",
    "\n",
    "            G_loss = - fake_out.mean()\n",
    "            G_loss.backward()\n",
    "            G_optimizer.step()\n",
    "\n",
    "            ##############\n",
    "            D_running_loss += abs(D_loss.item())\n",
    "            G_running_loss += abs(G_loss.item())\n",
    "            iter_num += 1\n",
    "            if i % 3== 0:\n",
    "                D_running_loss /= iter_num\n",
    "                G_running_loss /= iter_num\n",
    "                #print('iteration : %d, gp: %.2f' % (i, gradient_penalty))\n",
    "                databar.set_description('Epoch: %.3f D_loss: %.3f   G_loss: %.3f' % (epoch, D_running_loss ,G_running_loss))\n",
    "                iter_num = 0\n",
    "                D_running_loss = 0.0\n",
    "                G_running_loss = 0.0\n",
    "\n",
    "        D_epoch_losses.append(D_epoch_loss/tot_iter_num)\n",
    "        G_epoch_losses.append(G_epoch_loss/tot_iter_num)\n",
    "\n",
    "\n",
    "        check_point = {'G_net' : Gen.state_dict(), \n",
    "                       'G_optimizer' : G_optimizer.state_dict(),\n",
    "                       'D_net' : Disc.state_dict(),\n",
    "                       'D_optimizer' : D_optimizer.state_dict(),\n",
    "                       'D_epoch_losses' : D_epoch_losses,\n",
    "                       'G_epoch_losses' : G_epoch_losses,\n",
    "                       'fixed_noise': fixed_noise,\n",
    "                       'depth': Gen.depth,\n",
    "                       'alpha':Gen.alpha\n",
    "                       }\n",
    "        with T.no_grad():\n",
    "            Gen.eval()\n",
    "            T.save(check_point, check_point_dir + 'check_point_epoch_%d.pth' % (epoch))\n",
    "            T.save(Gen.state_dict(), weight_dir + 'G_weight_epoch_%d.pth' %(epoch))\n",
    "            out_imgs = Gen(fixed_noise).to(device)\n",
    "            out_grid = make_grid(out_imgs, normalize=True, nrow=4, scale_each=True, padding=int(0.5*(2**Gen.depth))).permute(1,2,0)\n",
    "            plt.imshow(out_grid.cpu())\n",
    "            plt.savefig(output_dir + 'size_%i_epoch_%d' %(size ,epoch))\n",
    "    depth_losses_g.append(np.mean(G_epoch_losses))\n",
    "    depth_losses_d.append(np.mean(D_epoch_losses))\n",
    "    #Increment depth step\n",
    "    if 2**(Gen.depth+2) <= out_res:\n",
    "        inc += 1\n",
    "        print(\"Growing network to size: \" + str(2**(Gen.depth+2)))\n",
    "        data_loader = DataLoader(dataset, **params)\n",
    "        tot_iter_num = tot_iter_num = (len(dataset)/batch_size)\n",
    "        Gen.inc_depth(epoch_*tot_iter_num)\n",
    "        Disc.inc_depth(epoch_*tot_iter_num)\n",
    "        size = 2**(Gen.depth+1)\n",
    "        print(\"Output Resolution: %d x %d\" % (size, size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02407ee-e17b-438e-80a6-32a0a18126d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd26dfe1-028f-43d6-8ec6-950001e1f936",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745cf4b9-62a9-46db-a619-6909f01f2a03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11471b4e-49e4-4812-9b21-9df80a7c62a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
