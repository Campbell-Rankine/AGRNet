{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d215e447-f153-4454-9e74-0a6ed59bb15c",
   "metadata": {},
   "source": [
    " # Train file \n",
    " ---\n",
    " For the model we will start by showing that we can purely train on depths 1 and 2 as those are the first instances containing every possible block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d77657c6-ca7b-4210-89a3-022f21ed9609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\campb\\anaconda3\\lib\\site-packages\\torchvision\\io\\image.py:11: UserWarning: Failed to load image Python extension: Could not find module 'C:\\Users\\campb\\anaconda3\\Lib\\site-packages\\torchvision\\image.pyd' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "### - imports - ###\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2 as cv\n",
    "import os\n",
    "import random\n",
    "import argparse\n",
    "### - other data augmentation imports - ### (if needed)\n",
    "### - Imports - ###\n",
    "import math\n",
    "import numpy as np\n",
    "import sklearn as sk #general imports, initial data preprocessing/OS stuff\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import os\n",
    "import torch as T\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim #Neural network imports, multiply data etc\n",
    "from torchvision.transforms import ToTensor\n",
    "import torchvision.models as models\n",
    "import torchvision\n",
    "import torch.nn.functional as F #Neural Network used in Comp4660 at ANU\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler #normalize data\n",
    "from sklearn.metrics import confusion_matrix #analysis\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid, save_image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from NetworkMain import D, G\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7179e90-3137-4cf6-9c6b-8e93fe29d356",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code will be added later when the file is converted to a python file\n",
    "\"\"\"parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--root', type=str, default='./', help='directory contrains the data and outputs')\n",
    "parser.add_argument('--epochs', type=int, default=40, help='training epoch number')\n",
    "parser.add_argument('--out_res', type=int, default=128, help='The resolution of final output image')\n",
    "parser.add_argument('--resume', type=int, default=0, help='continues from epoch number')\n",
    "parser.add_argument('--cuda', action='store_true', help='Using GPU to train')\n",
    "\n",
    "\n",
    "opt = parser.parse_args()\"\"\"\n",
    "\n",
    "root = '/Users/campb/Documents/PersonalProjects/AGRNet/'\n",
    "data_dir = root + 'Dataset/'\n",
    "check_point_dir = root + 'check_points/'\n",
    "output_dir = root + 'output/'\n",
    "weight_dir = root+ 'weight/'\n",
    "if not os.path.exists(check_point_dir):\n",
    "\tos.makedirs(check_point_dir)\n",
    "if not os.path.exists(output_dir):\n",
    "\tos.makedirs(output_dir)\n",
    "if not os.path.exists(weight_dir):\n",
    "\tos.makedirs(weight_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3f28971-e8b5-431e-93b8-d7e0dbbc57e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### - Global Variables - ###\n",
    "DFP = '/Users/campb/Documents/PersonalProjects/AGRNet/Dataset/Sample-'\n",
    "\n",
    "img_folder = '/Users/campb/Documents/PersonalProjects/AGRNet/Dataset/'\n",
    "\n",
    "NS = '/Sample-'\n",
    "\n",
    "image_format = 'RGB'\n",
    "\n",
    "schedule = [[5, 15, 25 ,35, 40],[16, 16, 16, 8, 4],[5, 5, 5, 1, 1]] #Epochs for each cycle num of epochs\n",
    "\n",
    "batch_size = schedule[1][0]\n",
    "\n",
    "growing = schedule[2][0]\n",
    "\n",
    "epochs = 40\n",
    "\n",
    "latent_size = 1024\n",
    "\n",
    "out_res = 1024\n",
    "\n",
    "lr = 1e-4\n",
    "\n",
    "lambd = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b0cca62-5f79-4e2b-88a4-cbe713331853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = T.device('cuda:0' if (T.cuda.is_available())  else 'cpu')\n",
    "\n",
    "transform = transforms.Compose([\n",
    "            transforms.Resize(out_res),\n",
    "            transforms.CenterCrop(out_res),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "            ])\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab319914-ad8f-4e7d-8277-2c86846b1ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create networks\n",
    "Disc = None\n",
    "Gen = None\n",
    "Disc = D(latent_size, out_res).to(device)\n",
    "Gen = G(latent_size, out_res).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43b42f5d-48e8-4639-9185-8fd1359519ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Noise for discriminator\n",
    "fixed_noise = T.randn(16, latent_size, 1, 1, device=device)\n",
    "#initialize optimizers\n",
    "D_optimizer = optim.Adam(Disc.parameters(), lr=lr, betas=(0, 0.99))\n",
    "G_optimizer = optim.Adam(Gen.parameters(), lr=lr, betas=(0, 0.99))\n",
    "#Metric variables\n",
    "D_running_loss = 0.0\n",
    "G_running_loss = 0.0\n",
    "iter_num = 0\n",
    "\n",
    "D_epoch_losses = []\n",
    "G_epoch_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31937179-b410-4458-a030-578806d24dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load with ImageFolder wrapper\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self,img_folder,names, transform):\n",
    "        self.transform = transform\n",
    "        self.image_names = names #Predetermined dataset\n",
    "        self.img_folder=img_folder\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_names)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "    \n",
    "        image=cv.imread(self.img_folder+self.image_names[index])\n",
    "        image=cv.cvtColor(image,cv.COLOR_BGR2RGB)\n",
    "        image=self.transform(image)\n",
    "        \n",
    "        return image\n",
    "\n",
    "assert(os.path.exists(DFP + str(1) + \".jpg\"))\n",
    "rawimgf = sorted(glob.glob(DFP + '*.jpg', recursive = True))\n",
    "### - image names - ###\n",
    "imnames = [i.split('/')[-1].split(\"t\")[-1][1:] for i in rawimgf]\n",
    "\n",
    "### - Global data loader Vars - ###\n",
    "norms = (0.5,0.5,0.5), (0.5,0.5,0.5)\n",
    "train_transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Resize((out_res, out_res)),\n",
    "                transforms.RandomHorizontalFlip(p=0.5)])\n",
    "# Parameters\n",
    "params = {'batch_size': schedule[1][0],\n",
    "          'shuffle': True,\n",
    "         'num_workers': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "374fa1ea-fc48-4646-83ff-53d980ec488a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fully Grown\n",
      "\n",
      "40 0\n"
     ]
    }
   ],
   "source": [
    "#Control variable\n",
    "resume = 0\n",
    "if resume != 0:\n",
    "    check_point = T.load(check_point_dir+'check_point_epoch_%i.pth' % resume)\n",
    "    fixed_noise = check_point['fixed_noise']\n",
    "    G_net.load_state_dict(check_point['G_net'])\n",
    "    D_net.load_state_dict(check_point['D_net'])\n",
    "    G_optimizer.load_state_dict(check_point['G_optimizer'])\n",
    "    D_optimizer.load_state_dict(check_point['D_optimizer'])\n",
    "    G_epoch_losses = check_point['G_epoch_losses']\n",
    "    D_epoch_losses = check_point['D_epoch_losses']\n",
    "    G_net.depth = check_point['depth']\n",
    "    D_net.depth = check_point['depth']\n",
    "    G_net.alpha = check_point['alpha']\n",
    "    D_net.alpha = check_point['alpha']\n",
    "\n",
    "\n",
    "try:\n",
    "    c = next(x[0] for x in enumerate(schedule[0]) if x[1]>resume)-1\n",
    "    batch_size = schedule[1][c]\n",
    "    growing = schedule[2][c]\n",
    "    dataset = ImageDataset(img_folder,imnames, train_transform)\n",
    "    # dataset = datasets.CelebA(data_dir, split='all', transform=transform)\n",
    "    data_loader = DataLoader(dataset, **params)\n",
    "\n",
    "    tot_iter_num = (len(dataset)/batch_size)\n",
    "    Gen.fade_iters = (1-Gen.alpha)/(schedule[0][c+1]-opt.resume)/(2*tot_iter_num)\n",
    "    Disc.fade_iters = (1-Disc.alpha)/(schedule[0][c+1]-opt.resume)/(2*tot_iter_num)\n",
    "\n",
    "\n",
    "except:\n",
    "    print('Fully Grown\\n')\n",
    "    c = -1\n",
    "    batch_size = schedule[1][c]\n",
    "    growing = schedule[2][c]\n",
    "\n",
    "    dataset = ImageDataset(img_folder,imnames, train_transform)\n",
    "    data_loader = DataLoader(dataset, **params)\n",
    "\n",
    "    tot_iter_num = (len(dataset)/batch_size)\n",
    "    print(schedule[0][c], resume)\n",
    "\n",
    "    if Gen.alpha < 1:\n",
    "        Gen.fade_iters = (1-Gen.alpha)/(opt.epochs-opt.resume)/(2*tot_iter_num)\n",
    "        Ddisc.fade_iters = (1-Disc.alpha)/(opt.epochs-opt.resume)/(2*tot_iter_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f11a8ab5-7099-4387-aa96-99c383b799f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Resolution: 4 x 4\n",
      "epoch: 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/11 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3072x1 and 1024x1024)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14160/1901313499.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m                 \u001b[0mDisc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m                 \u001b[0mnoise\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlatent_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m                 \u001b[0mfake\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m                 \u001b[0mfake_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDisc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfake\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m                 \u001b[0mreal_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDisc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\PersonalProjects\\AGRNet\\NetworkMain.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    226\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcell\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdepth\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdepth\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    229\u001b[0m         \u001b[0mcrgb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrgbs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdepth\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\PersonalProjects\\AGRNet\\NetworkMain.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msb\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1846\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1847\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3072x1 and 1024x1024)"
     ]
    }
   ],
   "source": [
    "### - Train Loop - ###\n",
    "size = 2**(Gen.depth+1)\n",
    "print(\"Output Resolution: %d x %d\" % (size, size))\n",
    "for epoch in range(1+resume, epochs+1):\n",
    "\tGen.train()\n",
    "\tD_epoch_loss = 0.0\n",
    "\tG_epoch_loss = 0.0\n",
    "\tif epoch-1 in schedule[0]:\n",
    "\n",
    "\t\tif (2 **(Gen.depth +1) < out_res):\n",
    "\t\t\tc = schedule[0].index(epoch-1)\n",
    "\t\t\tbatch_size = schedule[1][c]\n",
    "\t\t\tgrowing = schedule[2][0]\n",
    "\t\t\tdata_loader = DataLoader(dataset, **params)\n",
    "\t\t\ttot_iter_num = tot_iter_num = (len(dataset)/batch_size)\n",
    "\t\t\tGen.growing_net(growing*tot_iter_num)\n",
    "\t\t\tDisc.growing_net(growing*tot_iter_num)\n",
    "\t\t\tsize = 2**(Gen.depth+1)\n",
    "\t\t\tprint(\"Output Resolution: %d x %d\" % (size, size))\n",
    "\n",
    "\t\n",
    "\tprint(\"epoch: %i/%i\" % (int(epoch), int(epochs)))\n",
    "\tdatabar = tqdm(data_loader)\n",
    "\n",
    "\tfor i, samples in enumerate(databar):\n",
    "\t\t##  update D\n",
    "\t\tif size != out_res:\n",
    "\t\t\tsamples = F.interpolate(samples[0], size=size).to(device)\n",
    "\t\telse:\n",
    "\t\t\tsamples = samples[0].to(device)\n",
    "\t\tDisc.zero_grad()\n",
    "\t\tnoise = T.randn(samples.size(0), latent_size, 1, 1, device=device)\n",
    "\t\tfake = Gen(noise)\n",
    "\t\tfake_out = Disc(fake.detach())\n",
    "\t\treal_out = Disc(samples)\n",
    "\n",
    "\t\t## Gradient Penalty\n",
    "\n",
    "\t\teps = T.rand(samples.size(0), 1, 1, 1, device=device)\n",
    "\t\teps = eps.expand_as(samples)\n",
    "\t\tx_hat = eps * samples + (1 - eps) * fake.detach()\n",
    "\t\tx_hat.requires_grad = True\n",
    "\t\tpx_hat = Disc(x_hat)\n",
    "\t\tgrad = T.autograd.grad(\n",
    "\t\t\t\t\t\t\t\t\toutputs = px_hat.sum(),\n",
    "\t\t\t\t\t\t\t\t\tinputs = x_hat, \n",
    "\t\t\t\t\t\t\t\t\tcreate_graph=True\n",
    "\t\t\t\t\t\t\t\t\t)[0]\n",
    "\t\tgrad_norm = grad.view(samples.size(0), -1).norm(2, dim=1)\n",
    "\t\tgradient_penalty = lambd * ((grad_norm  - 1)**2).mean()\n",
    "\n",
    "\t\t###########\n",
    "\n",
    "\t\tD_loss = fake_out.mean() - real_out.mean() + gradient_penalty\n",
    "\n",
    "\t\tD_loss.backward()\n",
    "\t\tD_optimizer.step()\n",
    "\n",
    "\t\t##\tupdate G\n",
    "\n",
    "\t\tGen.zero_grad()\n",
    "\t\tfake_out = Disc(fake)\n",
    "\n",
    "\t\tG_loss = - fake_out.mean()\n",
    "\n",
    "\t\tG_loss.backward()\n",
    "\t\tG_optimizer.step()\n",
    "\n",
    "\t\t##############\n",
    "\n",
    "\t\tD_running_loss += D_loss.item()\n",
    "\t\tG_running_loss += G_loss.item()\n",
    "\n",
    "\t\titer_num += 1\n",
    "\n",
    "\n",
    "\t\tif i % 500== 0:\n",
    "\t\t\tD_running_loss /= iter_num\n",
    "\t\t\tG_running_loss /= iter_num\n",
    "\t\t\tprint('iteration : %d, gp: %.2f' % (i, gradient_penalty))\n",
    "\t\t\tdatabar.set_description('D_loss: %.3f   G_loss: %.3f' % (D_running_loss ,G_running_loss))\n",
    "\t\t\titer_num = 0\n",
    "\t\t\tD_running_loss = 0.0\n",
    "\t\t\tG_running_loss = 0.0\n",
    "\n",
    "\t\t\n",
    "\tD_epoch_losses.append(D_epoch_loss/tot_iter_num)\n",
    "\tG_epoch_losses.append(G_epoch_loss/tot_iter_num)\n",
    "\n",
    "\n",
    "\tcheck_point = {'G_net' : Gen.state_dict(), \n",
    "\t\t\t\t   'G_optimizer' : G_optimizer.state_dict(),\n",
    "\t\t\t\t   'D_net' : Disc.state_dict(),\n",
    "\t\t\t\t   'D_optimizer' : D_optimizer.state_dict(),\n",
    "\t\t\t\t   'D_epoch_losses' : D_epoch_losses,\n",
    "\t\t\t\t   'G_epoch_losses' : G_epoch_losses,\n",
    "\t\t\t\t   'fixed_noise': fixed_noise,\n",
    "\t\t\t\t   'depth': Gen.depth,\n",
    "\t\t\t\t   'alpha':Gen.alpha\n",
    "\t\t\t\t   }\n",
    "\twith T.no_grad():\n",
    "\t\tGen.eval()\n",
    "\t\tT.save(check_point, check_point_dir + 'check_point_epoch_%d.pth' % (epoch))\n",
    "\t\tT.save(Gen.state_dict(), weight_dir + 'G_weight_epoch_%d.pth' %(epoch))\n",
    "\t\tout_imgs = Gen(fixed_noise)\n",
    "\t\tout_grid = make_grid(out_imgs, normalize=True, nrow=4, scale_each=True, padding=int(0.5*(2**Gen.depth))).permute(1,2,0)\n",
    "\t\tplt.imshow(out_grid.cpu())\n",
    "\t\tplt.savefig(output_dir + 'size_%i_epoch_%d' %(size ,epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02407ee-e17b-438e-80a6-32a0a18126d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
